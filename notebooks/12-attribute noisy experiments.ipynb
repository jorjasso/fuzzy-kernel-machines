{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import sys\n",
    "import os\n",
    "qprc_path = os.path.abspath(os.path.join('..'))\n",
    "if qprc_path not in sys.path:\n",
    "    sys.path.append(qprc_path)\n",
    "\n",
    "#from utils.plots import *\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import csv\n",
    "from scipy.stats import randint\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import seaborn as sns\n",
    "from kernelfuzzy.kernels import KBFkernelSymmetric\n",
    "from  kernelfuzzy.fuzzyset import FuzzySet\n",
    "from kernelfuzzy.fuzzysystem import *\n",
    "from sklearn.datasets.samples_generator import make_classification\n",
    "from sklearn.datasets import make_moons, make_circles,make_blobs,load_digits\n",
    "from sklearn.svm import SVC,NuSVC\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline,FeatureUnion\n",
    "from sklearn.metrics import accuracy_score\n",
    "import skfuzzy as fuzz # for FCM\n",
    "import pickle\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold, StratifiedKFold\n",
    "from c45 import C45\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler,RobustScaler, Normalizer,QuantileTransformer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "from fylearn.nfpc import FuzzyPatternClassifier\n",
    "from fylearn.garules import MultimodalEvolutionaryClassifier\n",
    "from fylearn.fpt import FuzzyPatternTreeTopDownClassifier\n",
    "\n",
    "from fylearn.nfpc import FuzzyPatternClassifier  #base class for fuzzy pattern classifiers (see parameters)\n",
    "from fylearn.garules import MultimodalEvolutionaryClassifier #learns rules using genetic algorithm\n",
    "from fylearn.fpt import FuzzyPatternTreeTopDownClassifier #builds fuzzy pattern trees using top-down method.\n",
    "from fylearn.frr import FuzzyReductionRuleClassifier # based on learning membership functions from min/max.\n",
    "from fylearn.fpcga import FuzzyPatternClassifierGA # optimizes membership functions globally.\n",
    "from fylearn.fpt import FuzzyPatternTreeClassifier # builds fuzzy pattern trees using bottom-up method.\n",
    "from experimentscripts.functions_experiment_attribute_noise import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/attributenoise/nn/attribute_noise_0_nn/wine-0an-nn/wine-5an-nc-5-2tst.dat\n",
      "../data/attributenoise/nn/attribute_noise_0_nn/wine-0an-nn/wine-5an-cn-5-1tra.dat\n",
      "../data/attributenoise/nn/attribute_noise_0_nn/wine-0an-nn/wine-5an-cn-5-3tra.dat\n",
      "../data/attributenoise/nn/attribute_noise_0_nn/wine-0an-nn/wine-5an-nc-5-4tst.dat\n",
      "../data/attributenoise/nn/attribute_noise_0_nn/wine-0an-nn/wine-5an-cn-5-5tra.dat\n",
      "../data/attributenoise/nn/attribute_noise_0_nn/wine-0an-nn/wine-5an-nc-5-3tst.dat\n",
      "../data/attributenoise/nn/attribute_noise_0_nn/wine-0an-nn/wine-5an-cn-5-2tra.dat\n",
      "../data/attributenoise/nn/attribute_noise_0_nn/wine-0an-nn/wine-5an-nc-5-1tst.dat\n",
      "../data/attributenoise/nn/attribute_noise_0_nn/wine-0an-nn/wine-5an-nc-5-5tst.dat\n",
      "../data/attributenoise/nn/attribute_noise_0_nn/wine-0an-nn/wine-5an-cn-5-4tra.dat\n",
      "before eliminating duplicates  shape (890, 14)\n",
      "after eliminating duplicates  shape (178, 14)\n",
      "NSFS_KBF_symmetric , noise =  0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-05a7748a22ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m        ''' \n\u001b[1;32m     40\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m#or python experiments_attribute_noise.py -d iris -c knn -i 10 -tn nn -o ../experiments/attribute_noise -no 5 -ni 5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-05a7748a22ac>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m                                 \u001b[0;34m'classifier'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'NSFS_KBF_symmetric'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                                }\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mdo_experiments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment_description\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     '''\n",
      "\u001b[0;32m~/Documents/GITProjects/fuzzy-kernel-machines/experimentscripts/functions_experiment_attribute_noise.py\u001b[0m in \u001b[0;36mdo_experiments\u001b[0;34m(experiment_description)\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'NSFS_KBF_symmetric'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             list_results = list_results + classify(dataset_name, classifier, cv_params, pipe_KBF_symmetric, n_iter,\n\u001b[0;32m--> 307\u001b[0;31m                                                    inner_cv, outer_cv, X, y, noise)\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0;31m# -------------------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GITProjects/fuzzy-kernel-machines/experimentscripts/functions_experiment_attribute_noise.py\u001b[0m in \u001b[0;36mclassify\u001b[0;34m(dataset_name, classifier, cv_params, pipe, n_iter, inner_cv, outer_cv, X, y, noise)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0mnested_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mouter_cv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/fuzzy-kernels/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    388\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m                                 error_score=error_score)\n\u001b[0m\u001b[1;32m    391\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/fuzzy-kernels/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 236\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/fuzzy-kernels/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/fuzzy-kernels/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/fuzzy-kernels/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/fuzzy-kernels/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/fuzzy-kernels/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    experiment_description={'noise_level':[0,5,10,15,20],\n",
    "                                'type_noise' :'nn', #options are nn, nc, cn\n",
    "                                'dataset_name':'iris',\n",
    "                                'n_iter':10,\n",
    "                                'output_dir':'../experiments/attribute_noise',\n",
    "                                'n_splits_outter':5,\n",
    "                                'n_splits_inner':5,\n",
    "                                'classifier':'NSFS_KBF_symmetric'\n",
    "                               }\n",
    "    do_experiments(experiment_description)\n",
    "    \n",
    "    '''\n",
    "    list_classifiers=['NSFS_NS','NSFS_KBF_symmetric',\n",
    "                      'C4.5','bagC45',\n",
    "                      'svmRBF','knn',\n",
    "                     'FuzzyPatternClassifier','MultimodalEvolutionaryClassifier',\n",
    "                     'FuzzyPatternTreeTopDownClassifier','FuzzyReductionRuleClassifier',\n",
    "                     'FuzzyPatternClassifierGA','FuzzyPatternTreeClassifier','lr','rf','mlp','sgd'\n",
    "                     ]\n",
    "    \n",
    "    list_datasets=['iris','wine','sonar','glass','heart',\n",
    "                   'ecoli','ionosphere','wdbc','pima','contraceptive',\n",
    "                   'yeast','segment','spambase','page-blocks','satimage',\n",
    "                   'thyroid','ring','twonorm','penbased']\n",
    "    \n",
    "    for classifier in list_classifiers:\n",
    "        experiment_description={'noise_level':[0,5,10,15,20],\n",
    "                                'type_noise' :'nn', #options are nn, nc, cn\n",
    "                                'dataset_name':'iris',\n",
    "                                'n_iter':10,\n",
    "                                'output_dir':'../experiments/attribute_noise',\n",
    "                                'n_splits_outter':5,\n",
    "                                'n_splits_inner':5,\n",
    "                                #'classifier':list_classifiers[3],\n",
    "                                'classifier':classifier\n",
    "                               }\n",
    "        do_experiments(experiment_description)\n",
    "       ''' \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    \n",
    "#or python experiments_attribute_noise.py -d iris -c knn -i 10 -tn nn -o ../experiments/attribute_noise -no 5 -ni 5\n",
    "#wine 0 [0.76744186 0.65116279 0.97674419 1.         0.88095238]\n",
    "# noise =  5 [1.         0.97674419 0.95348837 0.95238095 0.85714286]\n",
    "# noise =  10 [0.95348837 0.93023256 0.97674419 0.97619048 0.92857143]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_sns(df,list_classifiers):\n",
    "    df_plot= df[df.classifier.isin(list_classifiers)]\n",
    "    sns.set(style=\"darkgrid\")\n",
    "    #g=sns.lineplot(x=\"noise\", y=\"accuracy\",\n",
    "    #               hue=\"classifier\", hue_order=list_classifiers,\n",
    "    #               style=\"classifier\",style_order=list_classifiers,\n",
    "    #               data=df_plot)\n",
    "    g=sns.lineplot(x=\"noise\", y=\"accuracy\", hue=\"classifier\",hue_order=list_classifiers,\n",
    "                   style=\"classifier\",style_order=list_classifiers,\n",
    "                   err_style=\"band\", \n",
    "                   ci='sd', \n",
    "                   estimator=\"median\", \n",
    "                   data=df_plot)\n",
    "    g.set_xticks([0,5,10,15,20])\n",
    "\n",
    "    # Put the legend out of the figure\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.show()\n",
    "\n",
    "def plot_sns_pointplot(df,list_classifiers):\n",
    "    df_plot= df[df.classifier.isin(list_classifiers)]\n",
    "    sns.set(style=\"darkgrid\")\n",
    "    #sns.lineplot(x=\"dimension\", y=\"accuracy\",\n",
    "    #             hue=\"classifier\", hue_order=list_classifiers,\n",
    "    #             style=\"classifier\",style_order=list_classifiers,\n",
    "    #             data=df_plot)\n",
    "    sns.pointplot(x=\"noise\", y=\"accuracy\", data=df_plot,\n",
    "                 hue=\"classifier\", hue_order=list_classifiers,\n",
    "                 style=\"classifier\",style_order=list_classifiers,\n",
    "                 estimator=np.median,\n",
    "                 linestyles=\"--\",\n",
    "                 ci=None)\n",
    "    # Put the legend out of the figure\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.show()\n",
    "    \n",
    "#PLOTS NESTED CV\n",
    "import os\n",
    "from functools import reduce\n",
    "import seaborn as sns\n",
    "\n",
    "#reading all the results starting with 'results'\n",
    "list_classifiers=['NSFS_NS','NSFS_KBF_symmetric',\n",
    "                      'C4.5','bagC45',\n",
    "                      'svmRBF','knn',\n",
    "                     'FuzzyPatternClassifier','MultimodalEvolutionaryClassifier',\n",
    "                     'FuzzyPatternTreeTopDownClassifier','FuzzyReductionRuleClassifier',\n",
    "                     'FuzzyPatternClassifierGA','FuzzyPatternTreeClassifier','lr','rf','mlp','sgd'\n",
    "                 ]\n",
    "\n",
    "path = '../experiments/attribute_noise'\n",
    "#joining files\n",
    "files = [filename for filename in os.listdir(path) if filename.startswith(\"nn\")]\n",
    "l_df= [pd.read_csv(path+'/'+file,index_col=0)  for file in files]\n",
    "df_results_non_nested = reduce(lambda left,right: pd.merge(left,right,on=['noise','trial'],left_index=True), l_df)\n",
    "#print(df_results_non_nested)\n",
    "#melt\n",
    "df = df_results_non_nested.copy()\n",
    "df = pd.melt(df, id_vars=['trial','noise'], value_vars=list_classifiers,\n",
    "             var_name='classifier', value_name='accuracy')\n",
    "df = df.sort_values(by='noise')\n",
    "    \n",
    "#ploting NSFS classifiers vs classical classifiers I\n",
    "#-------------------------------------------------\n",
    "#plt.figure(figsize=(20, 10))\n",
    "list_classifiers=['NSFS_NS','NSFS_KBF_symmetric','lr','svmRBF','knn',]\n",
    "plot_sns_pointplot(df,list_classifiers)\n",
    "list_classifiers=['NSFS_NS','NSFS_KBF_symmetric','rf','mlp','sgd']\n",
    "plot_sns_pointplot(df,list_classifiers)\n",
    "\n",
    "list_classifiers=['NSFS_NS','NSFS_KBF_symmetric','C4.5','bagC45']\n",
    "plot_sns_pointplot(df,list_classifiers)\n",
    "\n",
    "list_classifiers=['NSFS_NS','NSFS_KBF_symmetric','FuzzyPatternClassifier',\n",
    "                 'MultimodalEvolutionaryClassifier',\n",
    "                     'FuzzyPatternTreeTopDownClassifier']\n",
    "plot_sns_pointplot(df,list_classifiers)\n",
    "\n",
    "list_classifiers=['NSFS_NS','NSFS_KBF_symmetric','FuzzyReductionRuleClassifier',\n",
    "                     'FuzzyPatternClassifierGA','FuzzyPatternTreeClassifier']\n",
    "plot_sns_pointplot(df,list_classifiers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sklearn bug, see github issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston,load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, QuantileTransformer\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "data = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['data'], data['target'])\n",
    "inner_cv = KFold(n_splits=2, shuffle=True, random_state=0)\n",
    "outer_cv = KFold(n_splits=2, shuffle=True, random_state=0)\n",
    "\n",
    "#######\n",
    "scalers_to_test = [MinMaxScaler(), None]\n",
    "pipe_KBF_symmetric = Pipeline([('scaler', MinMaxScaler()),\n",
    "                               ('Fuzzifier', NonSingletonFuzzifier(constant_std=True)),\n",
    "                               ('kernel', KBFkernelSymmetric()),\n",
    "                               ('svm', SVC())])\n",
    "\n",
    "cv_params = {'scaler': scalers_to_test,\n",
    "             'Fuzzifier__std_proportion': np.arange(0.01, np.std(X_train), 0.1),\n",
    "             'kernel__param': 2.0 ** np.arange(-20, 1),\n",
    "             'svm__kernel': ['precomputed'],\n",
    "             'svm__C': 2.0 ** np.arange(-15, 15)}\n",
    "\n",
    "clf = RandomizedSearchCV(pipe_KBF_symmetric, cv_params, cv=inner_cv, verbose=1, n_jobs=-1, n_iter=3)\n",
    "nested_score = cross_val_score(clf, X=X_train, y=y_train, cv=outer_cv,n_jobs=-1)\n",
    "print(nested_score)\n",
    "\n",
    "#\n",
    "\n",
    "cv_params = [dict([('scaler',[scalers_to_test[0]]),\n",
    "                   ('Fuzzifier__std_proportion', np.arange(0.01, np.std(MinMaxScaler().fit(X_train).transform(X_train)), 0.1)),\n",
    "                   ('kernel__param', 2.0 ** np.arange(-20, 1)),\n",
    "                   ('svm__kernel', ['precomputed']),\n",
    "                   ('svm__C', 2.0 ** np.arange(-15, 15))]),\n",
    "             dict([('scaler',[scalers_to_test[1]]),\n",
    "                   ('Fuzzifier__std_proportion', np.arange(0.01, np.std(X_train), 0.1)),\n",
    "                   ('kernel__param', 2.0 ** np.arange(-20, 1)),\n",
    "                   ('svm__kernel', ['precomputed']),\n",
    "                   ('svm__C', 2.0 ** np.arange(-15, 15))])\n",
    "                    ]\n",
    "\n",
    "cv_params = [\n",
    "        {'scaler': [scalers_to_test[0]],\n",
    "         'Fuzzifier__std_proportion': np.arange(0.01, np.std(MinMaxScaler().fit(X_train).transform(X_train)), 0.1),\n",
    "         'kernel__param':  2.0 ** np.arange(-20, 1),\n",
    "         'svm__kernel': ['precomputed'],\n",
    "         'svm__C': 2.0 ** np.arange(-15, 15)},\n",
    "        {'scaler': [scalers_to_test[1]],\n",
    "         'Fuzzifier__std_proportion': np.arange(0.01, np.std(MinMaxScaler().fit(X_train).transform(X_train)), 0.1),\n",
    "         'kernel__param':  2.0 ** np.arange(-20, 1),\n",
    "         'svm__kernel': ['precomputed'],\n",
    "         'svm__C': 2.0 ** np.arange(-15, 15)},\n",
    "        ]\n",
    "clf = RandomizedSearchCV(pipe_KBF_symmetric, cv_params, cv=inner_cv, verbose=1, n_jobs=-1, n_iter=3)\n",
    "nested_score = cross_val_score(clf, X=X_train, y=y_train, cv=outer_cv,n_jobs=-1)\n",
    "print(nested_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## posted on github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, QuantileTransformer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import  cross_val_score, KFold,RandomizedSearchCV\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data \n",
    "y = iris.target\n",
    "pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('svm', SVC())\n",
    "        ])\n",
    "\n",
    "params = {'scaler': [StandardScaler(), MinMaxScaler(),RobustScaler(),None],\n",
    "          'svm__C': 2.0 ** np.arange(-15, 15)}\n",
    "#nested cv\n",
    "inner_cv = KFold(n_splits=3, shuffle=True, random_state=0)\n",
    "outer_cv = KFold(n_splits=3, shuffle=True, random_state=0)\n",
    "clf = RandomizedSearchCV(pipe, params, cv=inner_cv, verbose=1, n_jobs=-1, n_iter=3)\n",
    "nested_score = cross_val_score(clf, X=X, y=y, cv=outer_cv,n_jobs=-1)\n",
    "print(nested_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import sys\n",
    "import numpy\n",
    "numpy.set_printoptions(threshold=sys.maxsize)\n",
    "iris = load_iris()\n",
    "print(iris.data)\n",
    "df = pd.DataFrame(data= np.c_[iris['data'], iris['target']],\n",
    "                     columns= iris['feature_names'] + ['target'])\n",
    "print('duplicates :{}'.format(df[df.duplicated(keep=False)]))\n",
    "\n",
    "print(df.head())\n",
    "print(df.drop_duplicates().reset_index(drop=True).shape)\n",
    "print(df.drop_duplicates().shape)\n",
    "print('len df', df.shape)\n",
    "print('duplicates', pd.DataFrame.duplicated(df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generating strings for experiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "export PATH=$PATH:/home/jorjasso/anaconda3/bin && source activate fuzzyKernels  && screen -d -m python experiments_attribute_noise.py -d page-blocks -c bagC45 -i 10 -tn nn -o ../experiments/attribute_noise -no 5 -ni 5\n"
     ]
    }
   ],
   "source": [
    "#python experiments_attribute_noise.py -d iris -c knn -i 10 -tn nn -o ../experiments/attribute_noise -no 5 -ni 5\n",
    "list_classifiers=['NSFS_NS','NSFS_KBF_symmetric',\n",
    "                      'C4.5','bagC45',\n",
    "                      'svmRBF','knn',\n",
    "                     'FuzzyPatternClassifier','MultimodalEvolutionaryClassifier',\n",
    "                     'FuzzyPatternTreeTopDownClassifier','FuzzyReductionRuleClassifier',\n",
    "                     'FuzzyPatternClassifierGA','FuzzyPatternTreeClassifier','lr','rf','mlp','sgd'\n",
    "                     ]\n",
    "\n",
    "list_datasets=['iris','wine','sonar','glass','heart',\n",
    "                   'ecoli','ionosphere','wdbc','pima','contraceptive',\n",
    "                   'yeast','segment','spambase','page-blocks','satimage',\n",
    "                   'thyroid','ring','twonorm','penbased']\n",
    "\n",
    "list_classifiers=['bagC45']\n",
    "\n",
    "list_datasets=['page-blocks']\n",
    "\n",
    "str_exp='export PATH=$PATH:/home/jorjasso/anaconda3/bin && source activate fuzzyKernels '\n",
    "\n",
    "l_exp=[]\n",
    "for dataset in list_datasets:\n",
    "    for classifier in list_classifiers:\n",
    "        l_exp.append(' && screen -d -m python experiments_attribute_noise.py -d '+dataset+' -c '+classifier+' -i 10 -tn nn -o ../experiments/attribute_noise -no 5 -ni 5')\n",
    "\n",
    "print(len(l_exp))\n",
    "print(str_exp+''.join(l_exp))\n",
    "\n",
    "#verificar NSFS_NS con 'yeast','segment','spambase','page-blocks','satimage', puchkin, tolstoi, dostoievski, hulk1 hulk4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# optimizing code for kernel estimation: testing times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "---\n",
      "---\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Failed at nopython (convert to parfors)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-43fb6e3f4409>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0mgram_matrix_nonsingleton_gaussian_kernel_njit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmean_Y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msigma_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msigma_Y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;31m#func2_nb(mean_X,mean_Y,sigma_X,sigma_Y,1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m \u001b[0mfunc2_nb_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmean_Y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msigma_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msigma_Y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/numba/dispatcher.py\u001b[0m in \u001b[0;36m_compile_for_args\u001b[0;34m(self, *args, **kws)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0margtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypeof_pyval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTypingError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0;31m# Intercept typing error that may be due to an argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/numba/dispatcher.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, sig)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache_misses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m                 \u001b[0mcres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_overload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_overload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/numba/dispatcher.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, args, return_type)\u001b[0m\n\u001b[1;32m     78\u001b[0m                                       \u001b[0mimpl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                                       \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                                       flags=flags, locals=self.locals)\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0;31m# Check typing error if object mode is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtyping_error\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_pyobject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/numba/compiler.py\u001b[0m in \u001b[0;36mcompile_extra\u001b[0;34m(typingctx, targetctx, func, args, return_type, flags, locals, library)\u001b[0m\n\u001b[1;32m    738\u001b[0m     pipeline = Pipeline(typingctx, targetctx, library,\n\u001b[1;32m    739\u001b[0m                         args, return_type, flags, locals)\n\u001b[0;32m--> 740\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_extra\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/numba/compiler.py\u001b[0m in \u001b[0;36mcompile_extra\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlifted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlifted_from\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compile_bytecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompile_ir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_ir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlifted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlifted_from\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/numba/compiler.py\u001b[0m in \u001b[0;36m_compile_bytecode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m         \"\"\"\n\u001b[1;32m    698\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc_ir\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compile_core\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compile_ir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/numba/compiler.py\u001b[0m in \u001b[0;36m_compile_core\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m             \u001b[0;31m# Early pipeline completion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/numba/compiler.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, status)\u001b[0m\n\u001b[1;32m    244\u001b[0m                     \u001b[0;31m# No more fallback pipelines?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mis_final_pipeline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mpatched_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m                     \u001b[0;31m# Go to next fallback pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/numba/compiler.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, status)\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m                     \u001b[0mevent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m                     \u001b[0mstage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0m_EarlyPipelineCompletion\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/numba/compiler.py\u001b[0m in \u001b[0;36mstage_parfor_pass\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    492\u001b[0m         parfor_pass = ParforPass(self.func_ir, self.type_annotation.typemap,\n\u001b[1;32m    493\u001b[0m             self.type_annotation.calltypes, self.return_type)\n\u001b[0;32m--> 494\u001b[0;31m         \u001b[0mparfor_pass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstage_inline_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/numba/parfor.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0msimplify_CFG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc_ir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_prange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc_ir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc_ir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0mdprint_func_ir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc_ir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"after parfor pass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/numba/parfor.py\u001b[0m in \u001b[0;36m_convert_numpy\u001b[0;34m(self, blocks)\u001b[0m\n\u001b[1;32m    259\u001b[0m                         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExpr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mexpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'arrayexpr'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m                             instr = self._arrayexpr_to_parfor(\n\u001b[0;32m--> 261\u001b[0;31m                                 lhs, expr, avail_vars)\n\u001b[0m\u001b[1;32m    262\u001b[0m                     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_supported_npyreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m                         \u001b[0minstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reduction_to_parfor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/numba/parfor.py\u001b[0m in \u001b[0;36m_arrayexpr_to_parfor\u001b[0;34m(self, lhs, arrayexpr, avail_vars)\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0minit_block\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m         init_block.body = mk_alloc(self.typemap, self.calltypes, lhs,\n\u001b[0;32m--> 411\u001b[0;31m                                    tuple(size_vars), el_typ, scope, loc)\n\u001b[0m\u001b[1;32m    412\u001b[0m         \u001b[0mbody_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mbody_block\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/numba/ir_utils.py\u001b[0m in \u001b[0;36mmk_alloc\u001b[0;34m(typemap, calltypes, lhs, size_var, dtype, scope, loc)\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;31m# constant sizes need to be assigned to vars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             new_sizes = [convert_size_to_var(s, typemap, scope, loc, out)\n\u001b[0;32m---> 52\u001b[0;31m                          for s in size_var]\n\u001b[0m\u001b[1;32m     53\u001b[0m             \u001b[0mtuple_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mtuple_assign\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAssign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple_call\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/numba/ir_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;31m# constant sizes need to be assigned to vars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             new_sizes = [convert_size_to_var(s, typemap, scope, loc, out)\n\u001b[0;32m---> 52\u001b[0;31m                          for s in size_var]\n\u001b[0m\u001b[1;32m     53\u001b[0m             \u001b[0mtuple_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mtuple_assign\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAssign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple_call\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/numba/ir_utils.py\u001b[0m in \u001b[0;36mconvert_size_to_var\u001b[0;34m(size_var, typemap, scope, loc, nodes)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mnodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_assign\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnew_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msize_var\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Failed at nopython (convert to parfors)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numba as nb\n",
    "from numba import njit, prange\n",
    "import timeit\n",
    "\n",
    "def gram_matrix_nonsingleton_gaussian_kernel_njit(mean_X: np.ndarray,\n",
    "                                                  mean_Y: np.ndarray,\n",
    "                                                  sigma_X: np.ndarray,\n",
    "                                                  sigma_Y: np.ndarray,\n",
    "                                                  param: float) -> np.ndarray:\n",
    "    '''\n",
    "\n",
    "        Calculates the Gram matrix using the nonsingleton Gaussian kernel on fuzzy sets\n",
    "        optimized for Numba\n",
    "\n",
    "        Input:\n",
    "            mean_X, sigma_X:     matrix of parameters for fuzzy data X (Type: FuzzyData)\n",
    "            mean_Y, sigma_Y:     matrix of parameters for fuzzy data Y (Type: FuzzyData)\n",
    "            param:                  (Type: float) kernel parameter\n",
    "\n",
    "        Output:\n",
    "            (Type: numpy.ndarray) kernel matrix\n",
    "\n",
    "        '''\n",
    "\n",
    "    gram_matrix = np.zeros((mean_X.shape[0], mean_Y.shape[0]))\n",
    "\n",
    "\n",
    "    if mean_X is mean_Y:  # use symmetry property\n",
    "        N = mean_X.shape[0]\n",
    "\n",
    "        #for i in range(0, N):\n",
    "        for i in prange(N):\n",
    "            for j in range(i, N):\n",
    "\n",
    "                value = 1\n",
    "                for mean_x, mean_y, sigma_x, sigma_y in zip(mean_X[i, :], mean_Y[j, :], sigma_X[i, :], sigma_Y[j, :]):\n",
    "                    value = value * (np.exp(-0.5 * param * (mean_x - mean_y) ** 2 / (sigma_x ** 2 + sigma_y ** 2)))\n",
    "\n",
    "                gram_matrix[i, j] = value\n",
    "                gram_matrix[j, i] = value\n",
    "        # tikonov regularization\n",
    "        gram_matrix = gram_matrix + np.eye(N) * np.nextafter(0, 1)\n",
    "\n",
    "\n",
    "    else:  # X and Y are different\n",
    "        N = mean_X.shape[0]\n",
    "        M = mean_Y.shape[0]\n",
    "\n",
    "        #for i in range(0, N):\n",
    "        for i in prange(N):\n",
    "            for j in range(0, M):\n",
    "\n",
    "                value = 1\n",
    "                for mean_x, mean_y, sigma_x, sigma_y in zip(mean_X[i, :], mean_Y[j, :], sigma_X[i, :], sigma_Y[j, :]):\n",
    "                    value = value * (np.exp(-0.5 * param * (mean_x - mean_y) ** 2 / (sigma_x ** 2 + sigma_y ** 2)))\n",
    "\n",
    "                gram_matrix[i, j] = value\n",
    "\n",
    "    return gram_matrix\n",
    "\n",
    "\n",
    "func2_nb = nb.jit(nopython=True, nogil=True, parallel=False)(gram_matrix_nonsingleton_gaussian_kernel_njit)\n",
    "func2_nb_p = nb.jit(nopython=True, nogil=True, parallel=True)(gram_matrix_nonsingleton_gaussian_kernel_njit)\n",
    "\n",
    "val=50\n",
    "mean_X=mean_Y=sigma_X=sigma_Y=np.random.random_sample([val,val])\n",
    "\n",
    "\n",
    "#%timeit -n 10 gram_matrix_nonsingleton_gaussian_kernel_njit(mean_X,mean_Y,sigma_X,sigma_Y,1)\n",
    "print('---')\n",
    "#%timeit -n 10 func2_nb(mean_X,mean_Y,sigma_X,sigma_Y,1)\n",
    "print('---')\n",
    "#%timeit -n 10 func2_nb_p(mean_X,mean_Y,sigma_X,sigma_Y,1)\n",
    "print('---')\n",
    "gram_matrix_nonsingleton_gaussian_kernel_njit(mean_X,mean_Y,sigma_X,sigma_Y,1)\n",
    "#func2_nb(mean_X,mean_Y,sigma_X,sigma_Y,1)\n",
    "func2_nb_p(mean_X,mean_Y,sigma_X,sigma_Y,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "---\n",
      "---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "       [  0.,   1.,   1., ...,   1.,   1.,   1.],\n",
       "       [  0.,   1.,   2., ...,   2.,   2.,   2.],\n",
       "       ..., \n",
       "       [  0.,   1.,   2., ...,  47.,  47.,  47.],\n",
       "       [  0.,   1.,   2., ...,  47.,  48.,  48.],\n",
       "       [  0.,   1.,   2., ...,  47.,  48.,  49.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numba as nb\n",
    "from numba import njit, prange\n",
    "import timeit\n",
    "\n",
    "def gram_matrix_nonsingleton_gaussian_kernel_njit(mean_X: np.ndarray,\n",
    "                                                  mean_Y: np.ndarray,\n",
    "                                                  sigma_X: np.ndarray,\n",
    "                                                  sigma_Y: np.ndarray,\n",
    "                                                  param: float) -> np.ndarray:\n",
    "    '''\n",
    "\n",
    "        Calculates the Gram matrix using the nonsingleton Gaussian kernel on fuzzy sets\n",
    "        optimized for Numba\n",
    "\n",
    "        Input:\n",
    "            mean_X, sigma_X:     matrix of parameters for fuzzy data X (Type: FuzzyData)\n",
    "            mean_Y, sigma_Y:     matrix of parameters for fuzzy data Y (Type: FuzzyData)\n",
    "            param:                  (Type: float) kernel parameter\n",
    "\n",
    "        Output:\n",
    "            (Type: numpy.ndarray) kernel matrix\n",
    "\n",
    "        '''\n",
    "\n",
    "    gram_matrix = np.zeros((mean_X.shape[0], mean_Y.shape[0]))\n",
    "    N = mean_X.shape[0]\n",
    "    for i in prange(N):\n",
    "        for j in range(i, N):\n",
    "            value = i\n",
    "            gram_matrix[i, j] = value\n",
    "            gram_matrix[j, i] = value\n",
    "    #\n",
    "\n",
    "    return gram_matrix \n",
    "\n",
    "\n",
    "func2_nb = nb.jit(nopython=True, nogil=True, parallel=False)(gram_matrix_nonsingleton_gaussian_kernel_njit)\n",
    "func2_nb_p = nb.jit(nopython=True, nogil=True, parallel=True)(gram_matrix_nonsingleton_gaussian_kernel_njit)\n",
    "\n",
    "val=50\n",
    "mean_X=mean_Y=sigma_X=sigma_Y=np.random.random_sample([val,val])\n",
    "\n",
    "\n",
    "#%timeit -n 10 gram_matrix_nonsingleton_gaussian_kernel_njit(mean_X,mean_Y,sigma_X,sigma_Y,1)\n",
    "print('---')\n",
    "#%timeit -n 10 func2_nb(mean_X,mean_Y,sigma_X,sigma_Y,1)\n",
    "#%timeit -n 10 func2_nb_p(mean_X,mean_Y,sigma_X,sigma_Y,1)\n",
    "print('---')\n",
    "gram_matrix_nonsingleton_gaussian_kernel_njit(mean_X,mean_Y,sigma_X,sigma_Y,1)\n",
    "#func2_nb(mean_X,mean_Y,sigma_X,sigma_Y,1)\n",
    "print('---')\n",
    "func2_nb_p(mean_X,mean_Y,sigma_X,sigma_Y,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
